import boto3
import csv
from io import StringIO

def lambda_handler(event, context):
    s3 = boto3.client('s3')
    dynamodb = boto3.client('dynamodb')
    
    bucket_name = '12200228rithvik'
    table_name = 'RithvikTable'
    
    # List all objects in the S3 bucket
    response = s3.list_objects_v2(Bucket=bucket_name)
    objects = response.get('Contents', [])
    
    # Filter and sort CSV objects by size
    csv_objects = [obj for obj in objects if obj['Key'].lower().endswith('.csv')]
    top_10_csv_objects = sorted(csv_objects, key=lambda x: x['Size'], reverse=True)[:10]
    
    # Process each CSV object
    for csv_obj in top_10_csv_objects:
        csv_content = s3.get_object(Bucket=bucket_name, Key=csv_obj['Key'])['Body'].read().decode('utf-8')
        csv_reader = csv.DictReader(StringIO(csv_content))
        
        row_count = 0
        for row in csv_reader:
            if row_count >= 10:
                break
            # Add items to DynamoDB
            dynamodb.put_item(
                TableName=table_name,
                Item={
                    'object_key': {'S': csv_obj['Key']},
                    'id': {'S': row['id']},
                    'name': {'S': row['name']},
                    'age': {'S': row['age']},
                    'email': {'S': row['email']}
                }
            )
            row_count += 1

    return {
        'statusCode': 200,
        'body': 'Top 10 CSV objects processed and stored in DynamoDB.'
    }
